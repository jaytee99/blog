# 3. The Build Process

Getting from source to executable code is very different in C++ from what you may be used to in other languages, and it's important to understand this in reasonable detail.

C++ uses a _compile and link_ model. Code is first _compiled_ from source to an intermediate form called _object code_, and then all the object code that makes up your executable is _linked_ with any libraries it may need.

This is how C works, and since Stroustrup based C++ on C, he used the same model. One major advantage, at least in the early days, was that it makes it possible to use code and libraries written in other languages. One disadvantage is that it can make the build process more complex.

There are three stages to building an executable: preprocessing, compilation and linking

You meet the main compilers in the next chapter, so I'll just note here that all the main contenders - g++, clang and the Microsoft compiler - all implement the same workflow.

> As an aside, the compilers we use now are actually suites of tools, where originally the three stages involved different tools. There was a preprocessor tool (confusingly called `cpp`) and a linker (called `ld`). You'll rarely see these used separately, but they are still around on Unix-family operating systems. Try typing `man ld` for more information than you're likely ever to need.


## There's No Runtime

This is a big one: unlike Java or .NET (or Python, for that matter), there's nothing in charge at runtime - it's just your code, running on its own. There's no VM, just your code and the operating system.

This has a number of consequences. I'll mention a couple here, and others as we come across them. First, if your program crashes, you won't get a helpful stack trace, because there's nothing to give you one. And for running tests, the test framework and runner have to be built into your code.

## Preprocessing

**Note:** this section gives anoverview of what the preprocessor is and what it is used for. See Appendix 1 for more details on how it works, and what you'll see in code.

The first step to creating executable code is to psss it through the _preprocessor_. This is a simple tool that's been around since the early days of C, and which is used to perform text editing tasks on your code. Instructions to the preprocessor, called _preprocessor directives_, start with a hash as the first non-whitespace character on a line. Note that the directives don't end with a semi-colon.

It can be used for all sorts of fancy things, but it is mostly used for three things:

1. File inclusion
2. Including boilerplate code
3. Conditional compilation

### Including Files

You'll see lines like this at the top of almost every C++ source file:

```
#include <foo.h>
```

The preprocessor will open the file `foo.h` and insert it's content into the source at this point. This is a recursive process, so if `foo.h` itself contains `#include` directives, they'll also be processed.

Note the use of angle brackets. There is a search path where the preprocessor looks for include files, analogous to the shell's path, and this says to use that path to look for `foo.h`.

You may also see double quotes being used, e.g. `"foo.h"`. This says to look for the file relative to the source files (in this case, in the same directory), and you can also specify absolute paths (e.g. "\home\julian\includes\foo.h").

It is commonly regarded as best practice to use angle brackets.

### Including Boilerplate Code

The `#define` directive lets you define a token, together with the text that will be substituted by the preprocessor. Wherever the preprocessor sees the token, it will substitute the text (except within comments or quoted strings).

The token you define can take arguments, which will be substituted into the text. A good place to see this used is in the Google Testtest framework, where you can define a test like this:

```
TEST(TestSuiteName, TestName) {
  ... test body ...
}
```

This sets up a chunk of boilerplate code needed to define a test, and substitutes in whatever you give as the suite and test names.

> It's a widely-obeyed convention that these _macros_ have names in capitals, so that you can tell they're not real function or variable names.

### Conditional Compilation

The third use, less common now than it used to be, is to use the preprocessor to selectively include blocks of code. This is especially prevalent in codebases that can be built for different architectures, where you might see something like this:

```
#ifdef WIN32
  ... Windows code ...
#endif
#ifdef LINUX
  ... Linux code ...
#endif
```

The symbols `WIN32` and `LINUX` can be defined on the command line when building the code, and so the preprocessor will only pass on to the compiler the lines within the blocks where the symbol has been defined.

> This conditional stuff can get complex, with conditionals deeply nested.

That's a brief overview - consult the appendix for more details.

## Compiling

Once the preprocessor has run on the code, the result is sent to the compiler.

> The output from the preprocessor is called a _translation unit_, so although everyone talks about sending source files to the compiler, it's more correct to say that translation units are sent to the compiler.

> You'll notice that preprocessor directives look nothing like C++. They are a separate language, and the compiler never sees them. They are usually commented out in the source.

The job of the compiler is basically to do a syntax check on the code, and convert it into a binary format. The output from compilation is an _object file_, which will have a `.o` (Linux and other Unixes) or `.obj` (Windows) extension.

This is the place where you'll see _syntax errors_, the simplest of which is missing a semicolon at the end of a line.

Unlike some other languages, there's no link between a file's name (or its location) and its content, and it is common to have code for a class split over several files. There is also no universally accepted naming convention for files, although companies often have their own.

One thing to note, which may seem unusual, is that each source code file in a build is compiled in isolation. You can define a function in `file_A.cpp` and use it in code in `file_B.cpp`. The compiler can check that the definition is good, and it can also check that the call to the function in `file_B.cpp` also looks good, but it doesn't cross-check between the two. That's the job of the _linker_.

> The compiler only seeing one file at a time may seem a real restriction, but when C++ was invented, typical machines had very little memory, and it wouldn't be possible to hold more than one file in memory at a time. This is also why you have to declare a function before you use it; memory might be so limited that you couldn't even have the whole file in memory, so the compiler would start from the top and work down, discaring lines once it had processed them. That's no longer a limitation, but it's still how things work.

## Linking

A C++ program can (and often does) consist of dozens or even hundreds of files. Each of these will have been compiled to an object file, and it's the job of the _linker_ to combine them into an executable, along with any library code that may be needed.

The linker is old: it predates C++ (and even C). I won't say more about the copmiler or linker here, because they are the topic of the next chapter.
